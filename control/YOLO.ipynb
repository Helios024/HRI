{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e5115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "home = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6e15a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics.yolo.utils.plotting import Annotator\n",
    "import cv2\n",
    "from IPython.display import display, Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "18c08d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(2)\n",
    "ret, frame = cap.read()\n",
    "cv2.imshow('Test',frame)\n",
    "cv2.waitKey(6000)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "71de514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get images \n",
    "# Open the default camera\n",
    "cap = cv2.VideoCapture(2)\n",
    "for i in range(302,303):\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    save_path = 'images'\n",
    "    filename = f'img{i}.jpg'\n",
    "    cv2.putText(frame,f\"Taking pic {i}\",(3,30),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_AA)\n",
    "    output_path = os.path.join(save_path,filename)\n",
    "    cv2.imshow('Hand Tracking',frame)\n",
    "    cv2.imwrite(output_path, frame)\n",
    "    cv2.waitKey(3000) #wait 3 seconds before taking picture\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c482c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.getcwd()\n",
    "model = YOLO(f'{home}/best.pt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b984ffc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"KibJQODpGB8o4aIgozIb\")\n",
    "project = rf.workspace(\"brunel-university-london\").project(\"box-detection-dbztg\")\n",
    "dataset = project.version(1).download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69db28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = os.path.join(home,'box-detection-1','data.yaml')\n",
    "!yolo task=detect mode=train model=yolov8s.pt data={datapath} epochs=80 imgsz=800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f59a396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_frame(frame,detect):\n",
    "    annotator = Annotator(frame)\n",
    "    for res in detect:\n",
    "        for box in res.boxes:\n",
    "            b= box.xyxy[0] #extract bounding box\n",
    "            if b[1] > 100:\n",
    "                c = box.cls\n",
    "                annotator.box_label(b,str(res.names[int(c)])+str(round(float(box.conf),2))) #annotate box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ac767a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dimensions(frame,detect):\n",
    "    dimensions = []\n",
    "    for res in detect:\n",
    "        for box in res.boxes:\n",
    "            b = box.xyxy[0]\n",
    "            x_min = b[0]  # Minimum x-coordinate\n",
    "            y_min = b[1]  # Minimum y-coordinate\n",
    "            x_max = b[2]  # Maximum x-coordinate\n",
    "            y_max = b[3]  # Maximum y-coordinate\n",
    "            width = x_max - x_min\n",
    "            height = y_max - y_min\n",
    "            dimensions.append((height,width))\n",
    "    print(dimensions)\n",
    "    return dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "33165b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 608x800 1 box, 482.1ms\n",
      "Speed: 9.0ms preprocess, 482.1ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor(181.4861), tensor(181.0936))]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('images/img301.jpg')\n",
    "detect = model.predict(source=img,conf=0.25,save=False)\n",
    "annotate_frame(img,detect)\n",
    "get_dimensions(img,detect)\n",
    "cv2.imshow('hehe',img)\n",
    "cv2.waitKey(15000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8fce91e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 608x800 2 boxs, 527.9ms\n",
      "Speed: 12.0ms preprocess, 527.9ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 box, 470.9ms\n",
      "Speed: 12.0ms preprocess, 470.9ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 608x800 1 box, 483.2ms\n",
      "Speed: 10.0ms preprocess, 483.2ms inference, 1.0ms postprocess per image at shape (1, 3, 608, 800)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor(177.3120), tensor(178.0623))]\n"
     ]
    }
   ],
   "source": [
    "vidcap = cv2.VideoCapture(2)\n",
    "while vidcap.isOpened():\n",
    "    ret,frame = vidcap.read()\n",
    "    detect = model.predict(source=frame,conf=0.25,save=False)\n",
    "    annotate_frame(frame,detect)\n",
    "    cv2.imshow('Box Detection',frame)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "get_dimensions(frame,detect)\n",
    "vidcap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1de01b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c2c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "vidcap = cv2.VIdeoCapture(2)\n",
    "while vidcap.isOpened():\n",
    "    ret,frame = vidcap.read()\n",
    "    detect = model.predict(source)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
